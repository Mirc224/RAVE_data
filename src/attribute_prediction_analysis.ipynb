{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cfed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programovanie\\Python\\RAVE_data\\src\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from constants.rave_constants import *\n",
    "from constants.metrics_constants import *\n",
    "from utils.utility import load_rave_dataset\n",
    "from experiments.running_experiments import AttributePredictionResult\n",
    "from evaluation.attributes_prediction_evaluation import evaluate_predictions\n",
    "from sklearn.metrics import precision_score, recall_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "900546b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ID_KEY = 'sample_id'\n",
    "CLASSIFIER_KEY = 'classifier'\n",
    "VECTORIZER_KEY = 'vectorizer'\n",
    "EXAMPLE_COUNT_KEY = 'example_count'\n",
    "FOLD_NUMBER_KEY = 'fold_number'\n",
    "MODEL_SIZE_KEY = 'model_size'\n",
    "DATASET_VERSION_KEY = 'dataset_version'\n",
    "EXPERIMENT_NAME_KEY = 'experiment_name'\n",
    "PREDICTION_KEY = 'prediction'\n",
    "PREDICTION_BINARY_KEY = 'prediction_binary'\n",
    "ACTUAL_KEY = 'actual'\n",
    "ACTUAL_BINARY_KEY = 'actual_binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64a5c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_llm_predictior_info(experiment_name: str) -> dict:\n",
    "    splitted = experiment_name.split('_')\n",
    "    model_size = float(splitted[1].strip('b'))\n",
    "    examples = int(splitted[4].strip('shot'))\n",
    "    return {\n",
    "        VECTORIZER_KEY: \"\",\n",
    "        CLASSIFIER_KEY: splitted[0],\n",
    "        DATASET_VERSION_KEY: splitted[2],\n",
    "        FOLD_NUMBER_KEY: int(splitted[3]),\n",
    "        EXPERIMENT_NAME_KEY: f\"{splitted[0]}:{splitted[1]}-{splitted[4]}s\",\n",
    "        EXAMPLE_COUNT_KEY: examples,\n",
    "        MODEL_SIZE_KEY: model_size\n",
    "    }\n",
    "\n",
    "def parse_classifier_predictior_info(experiment_name: str) -> dict:\n",
    "    splitted = experiment_name.split('_')\n",
    "    return {\n",
    "        VECTORIZER_KEY: splitted[0],\n",
    "        CLASSIFIER_KEY: splitted[1],\n",
    "        DATASET_VERSION_KEY: splitted[2],\n",
    "        FOLD_NUMBER_KEY: int(splitted[3]),\n",
    "        EXPERIMENT_NAME_KEY: splitted[0] + \"_\" + splitted[1],\n",
    "        EXAMPLE_COUNT_KEY: 0,\n",
    "        MODEL_SIZE_KEY: 0\n",
    "    }\n",
    "\n",
    "def parse_base_name(experiment_name: str) -> dict:\n",
    "    return parse_llm_predictior_info(experiment_name) if experiment_name.endswith(\"shot\") else parse_classifier_predictior_info(experiment_name)\n",
    "\n",
    "def get_transformed_rows(base_name: str, prediction_list: list[dict]) -> list[dict]:\n",
    "    base_info = parse_base_name(base_name)\n",
    "    result_rows: list[dict] = []\n",
    "    for sample in prediction_list:\n",
    "        new_row = base_info | {\n",
    "            SAMPLE_ID_KEY: sample[AttributePredictionResult.ID],\n",
    "            PREDICTION_KEY: sample[AttributePredictionResult.PREDICTED_ATTRIBUTES],\n",
    "        }\n",
    "        result_rows.append(new_row)\n",
    "    return result_rows\n",
    "\n",
    "def create_binary_vector(ordered_attributes: list[str], provided_attributes: list[str]):\n",
    "    provided_set_lower = { attr.lower() for attr in provided_attributes if isinstance(attr, str)}\n",
    "    return [1 if attribute.lower() in provided_set_lower else 0 for attribute in ordered_attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5da30356",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_version = \"v2\"\n",
    "attribute_names_version = {\n",
    "    \"v1\": ALL_SELECTED_ATTRIBUTES,\n",
    "    \"v2\": ALL_SELECTED_ATTRIBUTES_V2,\n",
    "}\n",
    "TRANSFORMED_RESULT_FOLDER_PATH = './attribute_prediction_results'\n",
    "\n",
    "SELECTED_ATTRIBUTES = attribute_names_version[used_version]\n",
    "SORTED_ATTRIBUTES = sorted(SELECTED_ATTRIBUTES)\n",
    "\n",
    "dataset_path = f\"./dataset/rave_dataset_{used_version}.json\"\n",
    "rave_dataset = load_rave_dataset(dataset_path)\n",
    "for sample in rave_dataset:\n",
    "    sample.keep_selected_text_attributes(SELECTED_ATTRIBUTES)\n",
    "\n",
    "sample_attributes_dict = { sample.id : list(sample.text_attributes.keys()) for sample in rave_dataset }\n",
    "\n",
    "predicted_attributes_results: dict[str, list[dict]] = {}\n",
    "all_data_rows: list[dict] = []\n",
    "for filename in os.listdir(TRANSFORMED_RESULT_FOLDER_PATH):\n",
    "    file_path = os.path.join(TRANSFORMED_RESULT_FOLDER_PATH, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from file {filename}: {e}\")\n",
    "            continue\n",
    "    experiment_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    all_data_rows += get_transformed_rows(experiment_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "925902d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_data_rows)\n",
    "results_df[ACTUAL_KEY] = results_df[SAMPLE_ID_KEY].map(sample_attributes_dict)\n",
    "results_df[ACTUAL_BINARY_KEY] = results_df[ACTUAL_KEY].map(lambda x: create_binary_vector(SORTED_ATTRIBUTES, x))\n",
    "results_df[PREDICTION_BINARY_KEY] = results_df[PREDICTION_KEY].map(lambda x: create_binary_vector(SORTED_ATTRIBUTES, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87c09a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_evaluation_results: list[dict] = []\n",
    "\n",
    "for (classifier_name, model_size, vectorizer_name, experiment_name, fold_number, example_count), group in results_df.groupby([CLASSIFIER_KEY, MODEL_SIZE_KEY, VECTORIZER_KEY, EXPERIMENT_NAME_KEY, FOLD_NUMBER_KEY, EXAMPLE_COUNT_KEY]):\n",
    "    y_true = np.array(group[ACTUAL_BINARY_KEY].tolist())\n",
    "    y_pred = np.array(group[PREDICTION_BINARY_KEY].tolist())\n",
    "    res = {\n",
    "        CLASSIFIER_KEY: classifier_name,\n",
    "        MODEL_SIZE_KEY: model_size,\n",
    "        VECTORIZER_KEY: vectorizer_name,\n",
    "        EXPERIMENT_NAME_KEY: experiment_name,\n",
    "        FOLD_NUMBER_KEY: int(fold_number),\n",
    "        EXAMPLE_COUNT_KEY: int(example_count),\n",
    "    } | evaluate_predictions(y_true, y_pred)\n",
    "    approach_evaluation_results.append(res)\n",
    "evaluation_df = pd.DataFrame(approach_evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "103d3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_used = [MICRO_PRECISION_KEY, MICRO_RECALL_KEY, MICRO_F1_KEY,\n",
    "                MACRO_PRECISION_KEY, MACRO_RECALL_KEY, MACRO_F1_KEY,\n",
    "                WEIGHTED_PRECISION_KEY, WEIGHTED_RECALL_KEY, WEIGHTED_F1_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c3dc659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_size</th>\n",
       "      <th>example_count</th>\n",
       "      <th>micro_precision_mean</th>\n",
       "      <th>micro_recall_mean</th>\n",
       "      <th>micro_f1_mean</th>\n",
       "      <th>macro_precision_mean</th>\n",
       "      <th>macro_recall_mean</th>\n",
       "      <th>macro_f1_mean</th>\n",
       "      <th>weighted_precision_mean</th>\n",
       "      <th>weighted_recall_mean</th>\n",
       "      <th>weighted_f1_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bow_1-NN</td>\n",
       "      <td>1-NN</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840281</td>\n",
       "      <td>0.755435</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.619431</td>\n",
       "      <td>0.512001</td>\n",
       "      <td>0.542897</td>\n",
       "      <td>0.845951</td>\n",
       "      <td>0.755435</td>\n",
       "      <td>0.789906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bow_3-NN</td>\n",
       "      <td>3-NN</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892161</td>\n",
       "      <td>0.709368</td>\n",
       "      <td>0.789938</td>\n",
       "      <td>0.605083</td>\n",
       "      <td>0.416288</td>\n",
       "      <td>0.471898</td>\n",
       "      <td>0.866973</td>\n",
       "      <td>0.709368</td>\n",
       "      <td>0.767955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bow_5-NN</td>\n",
       "      <td>5-NN</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905749</td>\n",
       "      <td>0.688513</td>\n",
       "      <td>0.782098</td>\n",
       "      <td>0.581452</td>\n",
       "      <td>0.373656</td>\n",
       "      <td>0.430073</td>\n",
       "      <td>0.869676</td>\n",
       "      <td>0.688513</td>\n",
       "      <td>0.753023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bow_7-NN</td>\n",
       "      <td>7-NN</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913102</td>\n",
       "      <td>0.672665</td>\n",
       "      <td>0.774421</td>\n",
       "      <td>0.571110</td>\n",
       "      <td>0.353890</td>\n",
       "      <td>0.411692</td>\n",
       "      <td>0.871262</td>\n",
       "      <td>0.672665</td>\n",
       "      <td>0.740892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bow_LogReg</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961286</td>\n",
       "      <td>0.859675</td>\n",
       "      <td>0.907557</td>\n",
       "      <td>0.719894</td>\n",
       "      <td>0.552869</td>\n",
       "      <td>0.598662</td>\n",
       "      <td>0.939055</td>\n",
       "      <td>0.859675</td>\n",
       "      <td>0.887146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_5-NN</td>\n",
       "      <td>5-NN</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913512</td>\n",
       "      <td>0.649804</td>\n",
       "      <td>0.759250</td>\n",
       "      <td>0.680397</td>\n",
       "      <td>0.394260</td>\n",
       "      <td>0.473476</td>\n",
       "      <td>0.894345</td>\n",
       "      <td>0.649804</td>\n",
       "      <td>0.734791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_7-NN</td>\n",
       "      <td>7-NN</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928273</td>\n",
       "      <td>0.637479</td>\n",
       "      <td>0.755834</td>\n",
       "      <td>0.617985</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.439467</td>\n",
       "      <td>0.885784</td>\n",
       "      <td>0.637479</td>\n",
       "      <td>0.724127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_LogReg</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973817</td>\n",
       "      <td>0.688323</td>\n",
       "      <td>0.806387</td>\n",
       "      <td>0.553438</td>\n",
       "      <td>0.336092</td>\n",
       "      <td>0.393874</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.688323</td>\n",
       "      <td>0.763944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_SVM</td>\n",
       "      <td>SVM</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965413</td>\n",
       "      <td>0.851199</td>\n",
       "      <td>0.904616</td>\n",
       "      <td>0.699871</td>\n",
       "      <td>0.535948</td>\n",
       "      <td>0.576992</td>\n",
       "      <td>0.934089</td>\n",
       "      <td>0.851199</td>\n",
       "      <td>0.877367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950059</td>\n",
       "      <td>0.878683</td>\n",
       "      <td>0.912874</td>\n",
       "      <td>0.728258</td>\n",
       "      <td>0.627554</td>\n",
       "      <td>0.655851</td>\n",
       "      <td>0.934372</td>\n",
       "      <td>0.878683</td>\n",
       "      <td>0.898500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_name classifier vectorizer  model_size  example_count  \\\n",
       "0         bow_1-NN       1-NN        bow         0.0              0   \n",
       "1         bow_3-NN       3-NN        bow         0.0              0   \n",
       "2         bow_5-NN       5-NN        bow         0.0              0   \n",
       "3         bow_7-NN       7-NN        bow         0.0              0   \n",
       "4       bow_LogReg     LogReg        bow         0.0              0   \n",
       "..             ...        ...        ...         ...            ...   \n",
       "70      tfidf_5-NN       5-NN      tfidf         0.0              0   \n",
       "71      tfidf_7-NN       7-NN      tfidf         0.0              0   \n",
       "72    tfidf_LogReg     LogReg      tfidf         0.0              0   \n",
       "73       tfidf_SVM        SVM      tfidf         0.0              0   \n",
       "74   tfidf_XGBoost    XGBoost      tfidf         0.0              0   \n",
       "\n",
       "    micro_precision_mean  micro_recall_mean  micro_f1_mean  \\\n",
       "0               0.840281           0.755435       0.795533   \n",
       "1               0.892161           0.709368       0.789938   \n",
       "2               0.905749           0.688513       0.782098   \n",
       "3               0.913102           0.672665       0.774421   \n",
       "4               0.961286           0.859675       0.907557   \n",
       "..                   ...                ...            ...   \n",
       "70              0.913512           0.649804       0.759250   \n",
       "71              0.928273           0.637479       0.755834   \n",
       "72              0.973817           0.688323       0.806387   \n",
       "73              0.965413           0.851199       0.904616   \n",
       "74              0.950059           0.878683       0.912874   \n",
       "\n",
       "    macro_precision_mean  macro_recall_mean  macro_f1_mean  \\\n",
       "0               0.619431           0.512001       0.542897   \n",
       "1               0.605083           0.416288       0.471898   \n",
       "2               0.581452           0.373656       0.430073   \n",
       "3               0.571110           0.353890       0.411692   \n",
       "4               0.719894           0.552869       0.598662   \n",
       "..                   ...                ...            ...   \n",
       "70              0.680397           0.394260       0.473476   \n",
       "71              0.617985           0.366747       0.439467   \n",
       "72              0.553438           0.336092       0.393874   \n",
       "73              0.699871           0.535948       0.576992   \n",
       "74              0.728258           0.627554       0.655851   \n",
       "\n",
       "    weighted_precision_mean  weighted_recall_mean  weighted_f1_mean  \n",
       "0                  0.845951              0.755435          0.789906  \n",
       "1                  0.866973              0.709368          0.767955  \n",
       "2                  0.869676              0.688513          0.753023  \n",
       "3                  0.871262              0.672665          0.740892  \n",
       "4                  0.939055              0.859675          0.887146  \n",
       "..                      ...                   ...               ...  \n",
       "70                 0.894345              0.649804          0.734791  \n",
       "71                 0.885784              0.637479          0.724127  \n",
       "72                 0.900536              0.688323          0.763944  \n",
       "73                 0.934089              0.851199          0.877367  \n",
       "74                 0.934372              0.878683          0.898500  \n",
       "\n",
       "[75 rows x 14 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = evaluation_df.groupby([EXPERIMENT_NAME_KEY, CLASSIFIER_KEY, VECTORIZER_KEY, MODEL_SIZE_KEY, EXAMPLE_COUNT_KEY])[metrics_used].agg(['mean'])\n",
    "summary_df.columns = ['_'.join(col).strip() for col in summary_df.columns]\n",
    "summary_df = summary_df.reset_index()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f31b8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_order = ['LogReg', 'SVM', 'XGBoost', '1-NN', '3-NN', '5-NN', '7-NN', \"gemma\", \"gemma2\", 'llama3.1', 'llama3.2', 'mistral', 'qwen2', 'qwen2.5']\n",
    "vectorizer_order = ['bow', 'tfidf', 'embeddings', '']\n",
    "\n",
    "summary_df[CLASSIFIER_KEY] = pd.Categorical(summary_df[CLASSIFIER_KEY], categories=classifier_order, ordered=True)\n",
    "summary_df[VECTORIZER_KEY] = pd.Categorical(summary_df[VECTORIZER_KEY], categories=vectorizer_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0929842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_max_as_percent(col: pd.Series) -> pd.Series:\n",
    "    percentages = (col * 100).round(2)\n",
    "    max_val = percentages.max()\n",
    "    result = []\n",
    "    for val in percentages:\n",
    "        val_str = f\"{val:.2f}\"  # Format with 2 decimals and % sign\n",
    "        if val == max_val:\n",
    "            val_str = f\"\\\\textbf{{{val_str}}}\"\n",
    "        result.append(val_str)\n",
    "    return pd.Series(result)\n",
    "\n",
    "def transform_names(col: pd.Series) -> pd.Series:\n",
    "    result: list[str] = []\n",
    "    val: str = \"\"\n",
    "    for val in col:\n",
    "        if val.startswith(\"bow\"):\n",
    "            val = val.replace(\"bow\", \"BoW\")\n",
    "        if val.startswith(\"tfidf\"):\n",
    "            val = val.replace(\"tfidf\", \"TF-IDF\")\n",
    "        elif val.startswith(\"embeddings\"):\n",
    "            val = val.replace(\"embeddings\", \"Emb\")\n",
    "        result.append(f\"\\\\textbf{{{val}}}\")\n",
    "    return pd.Series(result)\n",
    "\n",
    "def transform_to_latex_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    metrics_used = [MICRO_PRECISION_KEY, MICRO_RECALL_KEY, MICRO_F1_KEY,\n",
    "                    MACRO_PRECISION_KEY, MACRO_RECALL_KEY, MACRO_F1_KEY,\n",
    "                    WEIGHTED_PRECISION_KEY, WEIGHTED_RECALL_KEY, WEIGHTED_F1_KEY]\n",
    "    latex_df = pd.DataFrame()\n",
    "    latex_df[\"Model\"] = transform_names(df[EXPERIMENT_NAME_KEY])\n",
    "    for metric in metrics_used:\n",
    "        latex_df[metric] = to_max_as_percent(df[metric + '_mean'])\n",
    "    return latex_df\n",
    "\n",
    "\n",
    "metrics_aliases = {\n",
    "    MICRO_PRECISION_KEY, \n",
    "    MICRO_RECALL_KEY, \n",
    "    MICRO_F1_KEY,\n",
    "    MACRO_PRECISION_KEY, \n",
    "    MACRO_RECALL_KEY, \n",
    "    MACRO_F1_KEY,\n",
    "    WEIGHTED_PRECISION_KEY, \n",
    "    WEIGHTED_RECALL_KEY, \n",
    "    WEIGHTED_F1_KEY\n",
    "}\n",
    "summary_sorted_df = summary_df.sort_values(by=[VECTORIZER_KEY, CLASSIFIER_KEY, MODEL_SIZE_KEY, EXAMPLE_COUNT_KEY])\n",
    "two_phase_df = summary_sorted_df.loc[summary_sorted_df[VECTORIZER_KEY] != \"\"]\n",
    "llm_df = summary_sorted_df.loc[summary_sorted_df[VECTORIZER_KEY] == \"\"]\n",
    "tp_latex_df = transform_to_latex_df(two_phase_df)\n",
    "llm_latex_df = transform_to_latex_df(llm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "369cad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Model & micro_precision & micro_recall & micro_f1 & macro_precision & macro_recall & macro_f1 & weighted_precision & weighted_recall & weighted_f1 \\\\\n",
      "\\midrule\n",
      "\\textbf{BoW_LogReg} & 96.13 & 85.97 & 90.76 & 71.99 & 55.29 & 59.87 & 93.91 & 85.97 & 88.71 \\\\\n",
      "\\textbf{BoW_SVM} & 94.51 & \\textbf{90.60} & 92.51 & \\textbf{79.29} & \\textbf{69.77} & \\textbf{72.43} & 94.32 & \\textbf{90.60} & \\textbf{91.93} \\\\\n",
      "\\textbf{BoW_XGBoost} & 95.36 & 90.39 & \\textbf{92.79} & 71.90 & 65.36 & 67.32 & 93.72 & 90.39 & 91.57 \\\\\n",
      "\\textbf{BoW_1-NN} & 84.03 & 75.54 & 79.55 & 61.94 & 51.20 & 54.29 & 84.60 & 75.54 & 78.99 \\\\\n",
      "\\textbf{BoW_3-NN} & 89.22 & 70.94 & 78.99 & 60.51 & 41.63 & 47.19 & 86.70 & 70.94 & 76.80 \\\\\n",
      "\\textbf{BoW_5-NN} & 90.57 & 68.85 & 78.21 & 58.15 & 37.37 & 43.01 & 86.97 & 68.85 & 75.30 \\\\\n",
      "\\textbf{BoW_7-NN} & 91.31 & 67.27 & 77.44 & 57.11 & 35.39 & 41.17 & 87.13 & 67.27 & 74.09 \\\\\n",
      "\\textbf{TF-IDF_LogReg} & 97.38 & 68.83 & 80.64 & 55.34 & 33.61 & 39.39 & 90.05 & 68.83 & 76.39 \\\\\n",
      "\\textbf{TF-IDF_SVM} & 96.54 & 85.12 & 90.46 & 69.99 & 53.59 & 57.70 & 93.41 & 85.12 & 87.74 \\\\\n",
      "\\textbf{TF-IDF_XGBoost} & 95.01 & 87.87 & 91.29 & 72.83 & 62.76 & 65.59 & 93.44 & 87.87 & 89.85 \\\\\n",
      "\\textbf{TF-IDF_1-NN} & 82.22 & 72.72 & 77.18 & 62.89 & 53.53 & 55.83 & 83.38 & 72.72 & 76.70 \\\\\n",
      "\\textbf{TF-IDF_3-NN} & 87.86 & 67.76 & 76.50 & 66.72 & 44.09 & 50.62 & 87.39 & 67.76 & 74.89 \\\\\n",
      "\\textbf{TF-IDF_5-NN} & 91.35 & 64.98 & 75.92 & 68.04 & 39.43 & 47.35 & 89.43 & 64.98 & 73.48 \\\\\n",
      "\\textbf{TF-IDF_7-NN} & 92.83 & 63.75 & 75.58 & 61.80 & 36.67 & 43.95 & 88.58 & 63.75 & 72.41 \\\\\n",
      "\\textbf{Emb_LogReg} & \\textbf{98.45} & 70.44 & 82.10 & 46.84 & 32.63 & 36.85 & 87.52 & 70.44 & 76.88 \\\\\n",
      "\\textbf{Emb_SVM} & 97.68 & 80.52 & 88.27 & 51.96 & 42.80 & 45.82 & 88.91 & 80.52 & 83.85 \\\\\n",
      "\\textbf{Emb_XGBoost} & 96.09 & 77.47 & 85.77 & 76.36 & 51.18 & 58.91 & \\textbf{94.43} & 77.47 & 83.99 \\\\\n",
      "\\textbf{Emb_1-NN} & 84.72 & 84.52 & 84.60 & 66.48 & 66.15 & 64.72 & 85.61 & 84.52 & 84.56 \\\\\n",
      "\\textbf{Emb_3-NN} & 89.79 & 80.59 & 84.92 & 69.18 & 56.41 & 60.39 & 88.72 & 80.59 & 83.77 \\\\\n",
      "\\textbf{Emb_5-NN} & 91.80 & 78.68 & 84.72 & 69.55 & 52.17 & 57.43 & 89.91 & 78.68 & 82.91 \\\\\n",
      "\\textbf{Emb_7-NN} & 92.55 & 77.12 & 84.12 & 68.23 & 48.65 & 54.40 & 89.69 & 77.12 & 81.74 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tp_latex_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3ad34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Model & micro_precision & micro_recall & micro_f1 & macro_precision & macro_recall & macro_f1 & weighted_precision & weighted_recall & weighted_f1 \\\\\n",
      "\\midrule\n",
      "\\textbf{gemma:2b-0shots} & 23.39 & 95.22 & 37.56 & 23.34 & 91.90 & 30.84 & 55.12 & 95.22 & 64.60 \\\\\n",
      "\\textbf{gemma:2b-1shots} & 42.34 & 55.79 & 48.11 & 23.55 & 32.36 & 25.38 & 54.66 & 55.79 & 54.60 \\\\\n",
      "\\textbf{gemma:2b-2shots} & 37.95 & 54.42 & 44.72 & 24.21 & 35.16 & 25.78 & 56.32 & 54.42 & 54.17 \\\\\n",
      "\\textbf{gemma:7b-0shots} & 48.58 & 44.55 & 46.46 & 39.63 & 43.66 & 33.33 & 73.10 & 44.55 & 50.04 \\\\\n",
      "\\textbf{gemma:7b-1shots} & 64.69 & 56.92 & 60.53 & 40.83 & 40.77 & 37.36 & 72.17 & 56.92 & 61.54 \\\\\n",
      "\\textbf{gemma:7b-2shots} & 66.88 & 59.69 & 63.06 & 40.78 & 35.64 & 35.01 & 70.21 & 59.69 & 62.79 \\\\\n",
      "\\textbf{gemma2:2b-0shots} & 26.86 & 78.04 & 39.95 & 25.58 & 77.30 & 31.23 & 57.81 & 78.04 & 61.19 \\\\\n",
      "\\textbf{gemma2:2b-1shots} & 41.40 & 63.99 & 50.24 & 30.08 & 53.18 & 32.69 & 63.57 & 63.99 & 60.52 \\\\\n",
      "\\textbf{gemma2:2b-2shots} & 54.49 & 64.56 & 59.07 & 32.84 & 43.18 & 33.43 & 66.03 & 64.56 & 63.24 \\\\\n",
      "\\textbf{gemma2:9b-0shots} & 73.71 & 57.24 & 64.44 & 60.78 & 53.33 & 50.28 & 88.48 & 57.24 & 63.31 \\\\\n",
      "\\textbf{gemma2:9b-1shots} & 75.19 & 67.34 & 71.04 & 53.76 & 51.17 & 48.19 & 81.87 & 67.34 & 71.40 \\\\\n",
      "\\textbf{gemma2:9b-2shots} & 72.33 & 71.16 & 71.73 & 47.34 & 53.30 & 46.12 & 78.44 & 71.16 & 72.43 \\\\\n",
      "\\textbf{gemma2:27b-0shots} & 90.23 & 71.63 & 79.86 & 75.43 & 61.76 & 63.27 & 93.34 & 71.63 & 77.82 \\\\\n",
      "\\textbf{gemma2:27b-1shots} & 88.05 & 71.72 & 79.04 & 68.69 & 57.81 & 58.61 & 90.37 & 71.72 & 77.77 \\\\\n",
      "\\textbf{gemma2:27b-2shots} & 87.27 & 75.81 & 81.13 & 67.00 & 57.59 & 58.05 & 88.76 & 75.81 & 80.13 \\\\\n",
      "\\textbf{llama3.1:8b-0shots} & 65.90 & 45.02 & 53.47 & 56.50 & 41.54 & 39.48 & 85.75 & 45.02 & 53.20 \\\\\n",
      "\\textbf{llama3.1:8b-1shots} & 70.12 & 63.79 & 66.79 & 52.61 & 53.29 & 47.60 & 79.63 & 63.79 & 68.29 \\\\\n",
      "\\textbf{llama3.1:8b-2shots} & 75.89 & 66.10 & 70.65 & 55.04 & 47.99 & 47.19 & 81.79 & 66.10 & 71.27 \\\\\n",
      "\\textbf{llama3.2:1b-0shots} & 23.11 & \\textbf{98.57} & 37.44 & 23.11 & \\textbf{95.30} & 30.97 & 54.67 & \\textbf{98.57} & 65.07 \\\\\n",
      "\\textbf{llama3.2:1b-1shots} & 44.28 & 44.00 & 43.99 & 28.46 & 32.48 & 26.68 & 60.34 & 44.00 & 49.47 \\\\\n",
      "\\textbf{llama3.2:1b-2shots} & 54.39 & 43.35 & 48.23 & 31.64 & 27.54 & 26.96 & 63.78 & 43.35 & 50.79 \\\\\n",
      "\\textbf{llama3.2:3b-0shots} & 24.72 & 91.42 & 38.92 & 23.99 & 86.38 & 30.89 & 56.03 & 91.42 & 64.30 \\\\\n",
      "\\textbf{llama3.2:3b-1shots} & 41.70 & 61.53 & 49.70 & 29.33 & 51.30 & 32.14 & 61.63 & 61.53 & 58.55 \\\\\n",
      "\\textbf{llama3.2:3b-2shots} & 56.42 & 60.67 & 58.47 & 33.67 & 41.53 & 33.54 & 66.16 & 60.67 & 60.56 \\\\\n",
      "\\textbf{mistral:7b-0shots} & 43.30 & 72.23 & 54.14 & 35.75 & 72.51 & 39.65 & 70.11 & 72.23 & 65.63 \\\\\n",
      "\\textbf{mistral:7b-1shots} & 59.58 & 64.99 & 62.13 & 41.71 & 54.00 & 42.60 & 72.13 & 64.99 & 65.59 \\\\\n",
      "\\textbf{mistral:7b-2shots} & 64.55 & 72.79 & 68.42 & 44.57 & 59.65 & 46.66 & 74.67 & 72.79 & 70.73 \\\\\n",
      "\\textbf{qwen2:0.5b-0shots} & 49.50 & 0.26 & 0.52 & 5.37 & 0.35 & 0.63 & 6.00 & 0.26 & 0.49 \\\\\n",
      "\\textbf{qwen2:0.5b-1shots} & 49.34 & 28.26 & 35.90 & 27.06 & 16.33 & 18.45 & 58.58 & 28.26 & 36.01 \\\\\n",
      "\\textbf{qwen2:0.5b-2shots} & 54.11 & 33.44 & 41.30 & 24.59 & 15.91 & 18.36 & 57.16 & 33.44 & 40.99 \\\\\n",
      "\\textbf{qwen2:1.5b-0shots} & 24.28 & 98.13 & 38.92 & 23.31 & 91.07 & 31.31 & 54.62 & 98.13 & 65.33 \\\\\n",
      "\\textbf{qwen2:1.5b-1shots} & 28.94 & 59.68 & 38.97 & 24.70 & 53.27 & 27.62 & 56.56 & 59.68 & 52.92 \\\\\n",
      "\\textbf{qwen2:1.5b-2shots} & 35.04 & 46.38 & 39.87 & 26.31 & 36.26 & 25.70 & 58.48 & 46.38 & 46.82 \\\\\n",
      "\\textbf{qwen2:7b-0shots} & 40.81 & 50.61 & 45.13 & 36.17 & 55.65 & 34.07 & 70.18 & 50.61 & 52.54 \\\\\n",
      "\\textbf{qwen2:7b-1shots} & 42.33 & 66.42 & 51.67 & 32.74 & 59.70 & 35.67 & 66.27 & 66.42 & 62.41 \\\\\n",
      "\\textbf{qwen2:7b-2shots} & 51.95 & 64.26 & 57.42 & 36.68 & 53.63 & 37.02 & 70.25 & 64.26 & 63.64 \\\\\n",
      "\\textbf{qwen2.5:0.5b-0shots} & 24.06 & 87.73 & 37.76 & 23.78 & 83.79 & 30.54 & 55.74 & 87.73 & 63.17 \\\\\n",
      "\\textbf{qwen2.5:0.5b-1shots} & 37.99 & 51.39 & 43.66 & 27.61 & 41.33 & 27.47 & 60.02 & 51.39 & 52.13 \\\\\n",
      "\\textbf{qwen2.5:0.5b-2shots} & 48.81 & 47.30 & 48.01 & 28.89 & 33.33 & 25.05 & 60.88 & 47.30 & 48.82 \\\\\n",
      "\\textbf{qwen2.5:1.5b-0shots} & 36.36 & 43.93 & 39.73 & 30.67 & 43.69 & 28.05 & 63.60 & 43.93 & 46.18 \\\\\n",
      "\\textbf{qwen2.5:1.5b-1shots} & 48.08 & 53.84 & 50.72 & 31.82 & 40.48 & 30.68 & 65.36 & 53.84 & 56.08 \\\\\n",
      "\\textbf{qwen2.5:1.5b-2shots} & 50.29 & 51.56 & 50.87 & 34.74 & 40.66 & 31.15 & 67.11 & 51.56 & 54.19 \\\\\n",
      "\\textbf{qwen2.5:3b-0shots} & 59.15 & 51.91 & 55.27 & 45.57 & 46.41 & 39.70 & 77.54 & 51.91 & 58.59 \\\\\n",
      "\\textbf{qwen2.5:3b-1shots} & 72.32 & 54.14 & 61.92 & 50.61 & 39.80 & 41.04 & 76.90 & 54.14 & 61.07 \\\\\n",
      "\\textbf{qwen2.5:3b-2shots} & 74.09 & 56.44 & 64.07 & 50.99 & 38.73 & 40.95 & 77.41 & 56.44 & 62.30 \\\\\n",
      "\\textbf{qwen2.5:7b-0shots} & 75.15 & 64.19 & 69.23 & 59.36 & 56.94 & 51.34 & 85.56 & 64.19 & 68.62 \\\\\n",
      "\\textbf{qwen2.5:7b-1shots} & 67.59 & 75.64 & 71.38 & 50.29 & 60.37 & 49.57 & 78.45 & 75.64 & 74.22 \\\\\n",
      "\\textbf{qwen2.5:7b-2shots} & 70.27 & 75.39 & 72.73 & 52.43 & 60.77 & 50.95 & 79.38 & 75.39 & 74.42 \\\\\n",
      "\\textbf{qwen2.5:14b-0shots} & 80.89 & 74.44 & 77.52 & 69.13 & 70.96 & 65.39 & 88.27 & 74.44 & 78.51 \\\\\n",
      "\\textbf{qwen2.5:14b-1shots} & 74.26 & 73.60 & 73.92 & 59.69 & 70.05 & 59.40 & 84.10 & 73.60 & 75.84 \\\\\n",
      "\\textbf{qwen2.5:14b-2shots} & 76.62 & 75.09 & 75.85 & 62.25 & 70.54 & 61.79 & 84.23 & 75.09 & 76.98 \\\\\n",
      "\\textbf{qwen2.5:32b-0shots} & 90.49 & 73.20 & 80.93 & \\textbf{75.78} & 70.70 & 69.37 & \\textbf{93.97} & 73.20 & 80.30 \\\\\n",
      "\\textbf{qwen2.5:32b-1shots} & 89.75 & 78.63 & 83.82 & 72.84 & 70.79 & 68.50 & 92.56 & 78.63 & 83.34 \\\\\n",
      "\\textbf{qwen2.5:32b-2shots} & \\textbf{90.81} & 80.11 & \\textbf{85.12} & 74.84 & 69.35 & \\textbf{69.55} & 92.05 & 80.11 & \\textbf{84.30} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_latex_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
